((0.7308104 , 0.26918963 ), 1), ((0.7309807 , 0.26901928 ), 0), ((0.6921569, 0.3078431 ), 0), ((0.7309858 , 0.26901418 ), 0), ((0.71622294, 0.283777   ), 0), ((0.73098314, 0.2690169  ), 0), ((0.7309894, 0.2690106 ), 0), ((0.41487494, 0.5851251  ), 1), ((0.73098963, 0.2690104  ), 0), ((0.73097795, 0.26902205 ), 0), ((0.3451115 , 0.65488845 ), 1), ((0.7309773 , 0.26902264 ), 0), ((0.26909024, 0.7309098  ), 1), ((0.7266488 , 0.27335125 ), 0), ((0.7308595, 0.2691405 ), 0), ((0.7309744, 0.2690256 ), 0), ((0.73098826, 0.2690117  ), 0), ((0.73099405, 0.26900595 ), 0), ((0.7309843 , 0.26901573 ), 0), ((0.7309819, 0.26901814 ), 0), ((0.7309905, 0.2690095 ), 0), ((0.73099214, 0.26900783 ), 0), ((0.41575533, 0.58424467 ), 0), ((0.73097247, 0.2690275  ), 0), ((0.7309854 , 0.26901463 ), 0), ((0.6154809 , 0.38451913 ), 0), ((0.7309889 , 0.26901114 ), 0), ((0.694416, 0.305584 ), 0), ((0.73099124, 0.2690087  ), 0), ((0.73061633, 0.2693837  ), 0), ((0.73095936, 0.26904058 ), 0), ((0.73099065, 0.26900938 ), 0), ((0.7309857 , 0.26901433 ), 0), ((0.73098165, 0.26901838 ), 0), ((0.26901272, 0.73098725 ), 1), ((0.26902452, 0.73097545 ), 1), ((0.7307031 , 0.26929682 ), 0), ((0.73098975, 0.26901025 ), 0), ((0.7309426, 0.2690574 ), 0), ((0.7309928, 0.2690072 ), 0), ((0.73067635, 0.26932365 ), 0), ((0.73095673, 0.26904327 ), 0), ((0.7309182 , 0.26908174 ), 0), ((0.7309344, 0.2690656 ), 0), ((0.7309809 , 0.26901916 ), 0), ((0.27225816, 0.72774184 ), 1), ((0.2690037, 0.7309963 ), 1), ((0.4619246, 0.5380754 ), 1), ((0.73086995, 0.26913002 ), 0), ((0.7309883 , 0.26901165 ),0), ((0.72759336, 0.27240667 ), 0), ((0.26902846, 0.7309715  ), 1), ((0.7309884, 0.2690116 ), 0), ((0.73090214, 0.26909783 ), 0), ((0.73099667, 0.2690033  ), 0), ((0.7309339 , 0.26906613 ), 0), ((0.73097587, 0.26902416 ), 0), ((0.73099375, 0.26900628 ), 0), ((0.7309168, 0.2690832 ), 0), ((0.7309646 , 0.26903537 ), 1), ((0.48373097, 0.516269   ), 1), ((0.7309311, 0.2690689 ), 0), ((0.7308729, 0.2691271 ), 0), ((0.73093367, 0.2690663  ), 0), ((0.7309585 , 0.26904148 ), 0), ((0.73099035, 0.26900965 ), 0), ((0.26901114, 0.7309889  ), 1), ((0.73098814, 0.26901188 ), 0), ((0.7309427 , 0.26905724 ), 0), ((0.26906386, 0.73093617 ), 1), ((0.26911557, 0.73088443 ), 1), ((0.7307792, 0.2692209 ), 0), ((0.73097515, 0.26902482 ), 0), ((0.7303645 , 0.26963547 ), 1), ((0.7307953 , 0.26920474 ), 1), ((0.73098767, 0.26901236 ), 0), ((0.7244083, 0.2755917 ), 0), ((0.49088988, 0.5091101  ), 1), ((0.7309908 , 0.26900923 ), 0), ((0.73099184, 0.26900816 ), 0), ((0.27453086, 0.7254692  ), 1), ((0.73098725, 0.26901275 ), 0), ((0.7309634 , 0.26903653 ), 0), ((0.7309844 , 0.26901558 ), 0), ((0.73097044, 0.26902962 ), 0), ((0.7090765 , 0.29092342 ), 0), ((0.73098636, 0.2690136  ), 0), ((0.730992  , 0.26900798 ), 0), ((0.7307769, 0.2692231 ), 0), ((0.5191751 , 0.48082486 ), 0), ((0.5267357 , 0.47326428 ), 1), ((0.7308236 , 0.26917645 ), 1), ((0.7309948 , 0.26900515 ), 0), ((0.725749  , 0.27425092 ), 1), ((0.73099154, 0.2690085  ), 0), ((0.7309777, 0.2690223 ), 1), ((0.73093796, 0.26906207 ), 1), ((0.73093456, 0.2690654  ), 0), ((0.7309893 , 0.26901066 ), 0)
6:((0.73094904, 0.26905093 ), 1),

fn == [
	(74, 0.26963547) - "the fresh gold has brought the american to excel" ???,
	(94, 0.27425092) - "Heidi and Spencer served-up... and invited customers to join in the effort.." ???, 

	(0, 0.26918963)  - "The Chamber has set up a committee to support..", its a bit less reasonable but can truely be understood as "the chamber support" and "a committee support",
		try to change 'set' to 'called'
	(91, 0.47326428) - "...so I can afford to take my twin sons to see AC/DC...", its less reasonable but can be understood as "i see" and "they see" and he gives almost 50 precent..,
		change main verb from 'take' to 'send'
	(96, 0.2690223)  - "the congress put together a coalition to oust the prime-minister", its less reasonable but can be understood as "congress oust" and "the coalition oust",

	(60, 0.26903537) - "I thank the universe for providing me", dont know how many 'for' marked advcls he saw in training maybe he doesnt know how to solve,
	(97, 0.26906207) - "the ABA rated him as qualified", dont know how many 'as' marked advcls he saw in training maybe he doesnt know how to solve,, 
		count how many examples are with different markers (Specificaly 'as' and 'for') and how they distribute regarding to classification, and maybe add new examples of these.
			leads: {'to': [49, 49], no_marker: [56, 3], 'from': [3, 22], 'as': [0, 21], 'by': [17, 0], 'after': [14, 0], 'in': [7, 1], 'for': [3, 3], 'before': [6, 0], 'being': [3, 2], 'while': [4, 0]}
			so, for the 'for' marker there are only 6 splited equally, nothing to learn there. but for the 'as' if we add information regarding the marker to the model, he might learn that 'as' is always classified 1 (as there are 21 examples and they are all pointing on class 1).
			
	(92, 0.26917645) - "He wanted all of jerusalm to remain..", this is hard because we marked all as the object but truly its jerusalm that is the subject (try changing the focus),
		change focus on jeruslam
		change 'wanted' to 'would want'
	(75, 0.26920474) - "The APA Office has just received a letter, requesting...", maybe this is hard because a letter is not animated,
		change focus on the Senator
		try to add 'as' marker to see its influence instead of 'no_marker'
		change 'received' to 'quoted' (or try to add or even remove??? the info of the main predicate somehow)
	(6, 0.26905093)  - "the deal gives FAW a platform to enter" this is actully very far connection and not really advcl (its "a platform to enter" and not "gives to enter"), 
		remove!
	]

tp == [(8, 0.5851251), (11, 0.65488845), (13, 0.7309098), (35, 0.73098725), (36, 0.73097545), (46, 0.72774184), (47, 0.7309963), (48, 0.5380754), (52, 0.7309715), (61, 0.516269), (67, 0.7309889), (70, 0.73093617), (71, 0.73088443), (78, 0.5091101), (81, 0.7254692)]

fp == [
	(23, 0.58424467) - "The FMF had called a meeting of club owners to choose ...", actully its the owners who choose.
		change focus to owners, and change to class to 1
	]


after ablation[1-3] (for comparison, and remember we removed index 6 so the rest are in offset -1):
(0.7308104 , 0.26918963 , 1), (0.7309807 , 0.26901928 , 0), (0.6921569, 0.3078431 , 0), (0.7309858 , 0.26901418 , 0), (0.71622294, 0.283777   , 0), (0.73098314, 0.2690169  , 0), (0.7309894, 0.2690106 , 0), (0.41487494, 0.5851251  , 1), (0.73098963, 0.2690104  , 0), (0.73097795, 0.26902205 , 0), (0.3451115 , 0.65488845 , 1), (0.7309773 , 0.26902264 , 0), (0.26909024, 0.7309098  , 1), (0.7266488 , 0.27335125 , 0), (0.7308595, 0.2691405 , 0), (0.7309744, 0.2690256 , 0), (0.73098826, 0.2690117  , 0), (0.73099405, 0.26900595 , 0), (0.7309843 , 0.26901573 , 0), (0.7309819 , 0.26901814 , 0), (0.7309905, 0.2690095 , 0), (0.73099214, 0.26900783 , 0), (0.30403528, 0.69596475 , 1), (0.73097247, 0.2690275  , 0), (0.7309854 , 0.26901463 , 0), (0.6154809 , 0.38451913 , 0), (0.7309889 , 0.26901114 , 0), (0.694416, 0.305584 , 0), (0.73099124, 0.2690087  , 0), (0.73061633, 0.2693837  , 0), (0.73095936, 0.26904058 , 0), (0.73099065, 0.26900938 , 0), (0.7309857 , 0.26901433 , 0), (0.73098165, 0.26901838 , 0), (0.26901272, 0.73098725 , 1), (0.26902452, 0.73097545 , 1), (0.7307031 , 0.26929682 , 0), (0.73098975, 0.26901025 , 0), (0.7309426, 0.2690574 , 0), (0.7309928, 0.2690072 , 0), (0.73067635, 0.26932365 , 0), (0.73095673, 0.26904327 , 0), (0.7309182 , 0.26908174 , 0), (0.7309344, 0.2690656 , 0), (0.7309809 , 0.26901916 , 0), (0.27225816, 0.72774184 , 1), (0.2690037, 0.7309963 , 1), (0.4619246, 0.5380754 , 1), (0.73086995, 0.26913002 , 0), (0.7309883 , 0.26901165 , 0), (0.72759336, 0.27240667 ,0), (0.26902846, 0.7309715  , 1), (0.7309884, 0.2690116 , 0), (0.73090214, 0.26909783 , 0), (0.73099667, 0.2690033  , 0), (0.7309339 , 0.26906613 , 0), (0.73097587, 0.26902416 , 0), (0.73099375, 0.26900628 , 0), (0.7309168, 0.2690832 , 0), (0.7309646 , 0.26903537 , 1), (0.48373097, 0.516269   , 1), (0.7309311, 0.2690689 , 0), (0.7308729, 0.2691271 , 0), (0.73093367, 0.2690663  , 0), (0.7309585 , 0.26904148 , 0), (0.73099035, 0.26900965 , 0), (0.26901114, 0.7309889  , 1), (0.73098814, 0.26901188 , 0), (0.7309427 , 0.26905724 , 0), (0.26906386, 0.73093617 , 1), (0.26911557, 0.73088443 , 1), (0.7307792, 0.2692209 , 0), (0.73097515, 0.26902482 , 0), (0.7303645 , 0.26963547 , 1), (0.73070556, 0.26929447 , 1), (0.73098767, 0.26901236 , 0), (0.7244083, 0.2755917 , 0), (0.49088988, 0.5091101  , 1), (0.7309908 , 0.26900923 , 0), (0.73099184, 0.26900816 , 0), (0.27453086, 0.7254692  , 1), (0.73098725, 0.26901275 , 0), (0.7309634 , 0.26903653 , 0), (0.7309844 , 0.26901558 , 0), (0.73097044, 0.26902962 , 0), (0.7090765 , 0.29092342 , 0), (0.73098636, 0.2690136  , 0), (0.730992  , 0.26900798 , 0), (0.7307769, 0.2692231 , 0), (0.5191751 , 0.48082486 , 0), (0.5267357 , 0.47326428 , 1), (0.7308101 , 0.26918992 , 1), (0.7309948 , 0.26900515 , 0), (0.725749  , 0.27425092 , 1), (0.73099154, 0.2690085  , 0), (0.7309777, 0.2690223 , 1), (0.73093796, 0.26906207 , 1), (0.73093456, 0.2690654  , 0), (0.7309893 ,0.26901066 , 0)

after ablation[4-6]
which means:
	1. the single fp (23) got much stronger since the focus change, 0.58424467 -> 0.69596475.
	2. removing the wrong example (6) is very influentive on the score (As we dont have much examples)
	3. fn that we changed their focus (75, 92) were improved very slightly (0.26920474 -> 0.26929447, 0.26917645 -> 0.26918992)
	4. if we change the main predicate in 91, from "take" to "send" we successfully change the classification predication (0.47326428 -> 0.5549045)
	5. changing some more verbs (0, 75, 92) didnt change the overall score but did improve slightly: (0: 26918963 -> 0.2697287, 75: 0.26929447 -> 0.32666948, 92: 0.26918992 -> 0.2693448)
	6. adding for 75 'as' marker fixed the classification predication (0.26929447 -> 0.7309772) (but this is interesting, as we would expect 97 to be classified correctly because it has a 'as' marker)
	7. changed 97's main predicate from 'rated' to 'described', only minor change: (0.26906207 -> 0.26913142)
	
